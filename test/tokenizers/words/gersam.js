/**
 * Talisman tokenizers/words/gersam tests
 * =======================================
 *
 */
import assert from 'assert';
import words from '../../../src/tokenizers/words/gersam';

describe('gersam', function() {
  it('should correctly tokenize words.', function() {
    const tests = [
      {
        lang: 'en',
        text: 'Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks.',
        tokens: ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']
      },
      {
        lang: 'en',
        text: 'They\'ll save and invest more.',
        tokens: ['They', '\'ll', 'save', 'and', 'invest', 'more', '.']
      },
      {
        lang: 'en',
        text: 'hi, my name can\'t hello,',
        tokens: ['hi', ',', 'my', 'name', 'can', '\'t', 'hello', ',']
      },
      {
        lang: 'en',
        text: '"Hello", Good sir (this is appaling)...',
        tokens: ['"', 'Hello', '"', ',', 'Good', 'sir', '(', 'this', 'is', 'appaling', ')', '.', '.', '.']
      },
      {
        lang: 'fr',
        text: "L'amour de l‚Äôamour na√Æt pendant l'√©t√©!",
        tokens: ['L\'', 'amour', 'de', 'l‚Äô', 'amour', 'na√Æt', 'pendant', 'l\'', '√©t√©', '!']
      },
      {
        lang: 'en',
        text: 'It all started during the 90\'s!',
        tokens: ['It', 'all', 'started', 'during', 'the', '90', '\'s', '!']
      },
      {
        lang: 'en',
        text: 'This is some it\'s sentence. This is incredible "ok" (very) $2,4 2.4 Aujourd\'hui This, is very cruel',
        tokens: ['This', 'is', 'some', 'it', '\'s', 'sentence', '.', 'This', 'is', 'incredible', '"', 'ok', '"', '(', 'very', ')', '$', '2,4', '2.4', 'Aujourd', '\'hui', 'This', ',', 'is', 'very', 'cruel']
      },
      {
        lang: 'fr',
        text: 'Il fait beau aujourd‚Äôhui sur la presqu\'√Æle.',
        tokens: ['Il', 'fait', 'beau', 'aujourd‚Äôhui', 'sur', 'la', 'presqu\'√Æle', '.']
      },
      {
        lang: 'it',
        text: 'O.N.U. La vie.est foutue.',
        tokens: ['O.N.U.', 'La', 'vie', '.', 'est', 'foutue', '.']
      },
      {
        lang: 'en',
        text: 'Mrs. Langley is back from the market.',
        tokens: ['Mrs.', 'Langley', 'is', 'back', 'from', 'the', 'market', '.']
      },
      {
        lang: 'fr',
        text: 'Les √â.U. sont nuls.',
        tokens: ['Les', '√â.U.', 'sont', 'nuls', '.']
      },
      {
        lang: 'en',
        text: 'This is a very nice cat üê±! No?',
        tokens: ['This', 'is', 'a', 'very', 'nice', 'cat', 'üê±', '!', 'No', '?']
      }
    ];

    tests.forEach(function({lang, text, tokens}) {
      assert.deepEqual(words(lang, text), tokens);
    });
  });
});
